#!/usr/bin/env python3

from __future__ import print_function
   
import numpy as np
import astropy.io.fits as fits
import astropy.io.ascii as ascii
import glob, os, shutil, warnings
import string, gc, time, copy
import argparse, datetime
import matplotlib.pyplot as pl
try:
  from mpi4py import MPI
  mpi=1
except:
  mpi=0

from mcalf.routines import hires_fitter as fitter

pl.rc('text', usetex=False)
pl.rcParams['font.size'] = 20

parser = argparse.ArgumentParser()
parser.add_argument('--debug', action='store_true')
parser.add_argument('config')
args = parser.parse_args()

configpars = fitter.readconfig(args.config)

if args.debug:
   print('DEBUG mode, increased verbosity')

#Create directories if necessary
if not os.path.isdir(configpars['chaindir']):
   os.makedirs(configpars['chaindir'])
if not os.path.isdir(configpars['plotdir']):
   os.makedirs(configpars['plotdir'])

if configpars['dofit']:

        with fitter.als_fitter(configpars['specfile'], configpars['wavefit'], configpars['linelist'], configpars['ncomp'], \
                                 nfill=configpars['nfill'], coldef=configpars['coldef'], contval=configpars['contval'], \
                                 specres=configpars['specres'], Nrange=configpars['Nrange'], brange=configpars['brange'], \
                                 zrange=configpars['zrange'], Nrangefill=configpars['Nrangefill'], \
                                 brangefill=configpars['brangefill'], wrangefill=configpars['wrangefill'], \
                                 Asymmlike=configpars['asymmlike'], debug= args.debug) as temp:

           if configpars['solver'] == 'polychord':
              
              import pypolychord
              from pypolychord.settings import PolyChordSettings
              
              settings = PolyChordSettings(temp.ndim, 0)
              settings.file_root = configpars['chainfmt'].format(configpars['nfill'])
              settings.base_dir = configpars['chaindir']
              if 'pcsettings' in configpars:
                 configsettings = configpars['pcsettings']
                 settings.nlive         = int(configsettings.get('nlive', 100))
                 settings.num_repeats   = int(configsettings.get('num_repeats', 20))
                 settings.precision_criterion = float(configsettings.get('precision_criterion', 1e-3))
                 settings.feedback      = int(configsettings.get('feedback', 1)) 
                 settings.do_clustering = configsettings.get('do_clustering', True)
                 settings.equals        = configsettings.get('equals', True)
                 settings.read_resume   = configsettings.get('read_resume', True)
                 settings.write_resume  = configsettings.get('write_resume', True)
                 settings.write_live    = configsettings.get('write_live', True)
                 settings.write_dead    = configsettings.get('write_dead', True)
                 settings.write_prior   = configsettings.get('write_prior', True)
                 settings.posteriors    = configsettings.get('posteriors', True)
                 settings.cluster_posteriors = configsettings.get('cluster_posteriors', True)
           
              # Run PolyChord
              
              print('Running polychord')
              t0 = datetime.datetime.now()
              output = pypolychord.run_polychord(temp.lnlhood_pc, temp.ndim, 0, settings, temp._scale_cube_pc)
              t1 = datetime.datetime.now()
              if mpi==1:
                if MPI.COMM_WORLD.rank==0:
                 print('Execution time {}'.format(t1-t0))
              else:
                 print('Execution time {}'.format(t1-t0))
           
           elif configpars['solver'] == 'dypolychord':
               
               import dyPolyChord.pypolychord_utils
               import dyPolyChord
               from pypolychord.settings import PolyChordSettings
               
               
               settings_dict = {'file_root': configpars['chainfmt'].format(configpars['nfill']),
                                'base_dir': configpars['chaindir'],
                                'nlive': 100} 
               
               dynamic_goal = 0.25 # whether to maximise parameter estimation or evidence accuracy.
               
               if 'pcsettings' in configpars:
                 configsettings = configpars['pcsettings']
                 settings_dict['nlive'] = int(configsettings['nlive'])
                 settings_dict['num_repeats']   = int(configsettings['num_repeats'])
                 settings_dict['precision_criterion'] = float(configsettings['precision_criterion'])
                 settings_dict['feedback']      = 0
                 settings_dict['do_clustering'] = configsettings['do_clustering']
                 settings_dict['equals']        = configsettings['equals']
                 settings_dict['read_resume']   = configsettings['read_resume']
                 settings_dict['write_resume']  = configsettings['write_resume']
                 settings_dict['write_live']    = configsettings['write_live']
                 settings_dict['write_dead']    = configsettings['write_dead']
                 settings_dict['write_prior']   = configsettings['write_prior']
                 settings_dict['posteriors']    = configsettings['posteriors']
                 settings_dict['cluster_posteriors'] = configsettings['cluster_posteriors']
                 dynamic_goal                   = float(configsettings['dynamic_goal'])
               
               # Make a callable for running PolyChord
               pypolychord_callable = dyPolyChord.pypolychord_utils.RunPyPolyChord(temp.lnlhood_pc, temp._scale_cube_pc, temp.ndim)

               # Run dyPolyChord
               dyPolyChord.run_dypolychord(pypolychord_callable, dynamic_goal, settings_dict,
                                           ninit=int(settings_dict['nlive']/5), nlive_const=int(settings_dict['nlive']),
                                           comm=MPI.COMM_WORLD)
               
             
           elif configpars['solver'] == 'multinest':
              
              import pymultinest
              
              out_fmt = configpars['chaindir']+'/'+configpars['chainfmt'].format(comp, configpars['nfill'])
              
              if 'mnsettings' in configpars:
                 configsettings = configpars['mnsettings']
                 if 'nlive' in configsettings:
                    nlive = int(configsettings['nlive'])
                 else:
                    nlive = 1000   
                 if 'samplingeff' in configsettings:
                    samplingeff = float(configsettings['samplingeff'])
                 else:
                    samplingeff = 0.3  
              
              t0 = datetime.datetime.now()
              pymultinest.run(temp.lnlhood_mn, temp._scale_cube_mn, temp.ndim, sampling_efficiency=samplingeff, resume=False, \
                   outputfiles_basename=out_fmt, verbose=True, multimodal=False, \
                   importance_nested_sampling=False, n_live_points=nlive, n_iter_before_update=100, \
                   evidence_tolerance=0.1)
              t1 = datetime.datetime.now()
              if mpi==1:
                if MPI.COMM_WORLD.rank==0:
                 print('Execution time {}'.format(t1-t0))
              else:
                 print('Execution time {}'.format(t1-t0))
               
           elif configpars['solver'] == 'dynesty':
               
               import dynesty
               
               out_fmt = configpars['chaindir']+'/'+configpars['chainfmt'].format(comp, configpars['nfill'])
               
               dsampler = dynesty.DynamicNestedSampler(temp.lnlhood_dy, temp._scale_cube_pc, temp.ndim, bound='none', method='unif')
               dsampler.run_nested()
               dresults = dsampler.results
               
               samples = dresults.samples  # samples
               weights = np.exp(dresults.logwt - dresults.logz[-1])  # normalized weights

               # Resample weighted samples.
               samples_equal = dyfunc.resample_equal(samples, weights)
               
               np.savetxt(out_fmt+'equal_weights.txt', samples_equal)               
               
           elif configpars['solver'] == 'jaxns':
               try:
                   import jax
                   import jax.numpy as jnp
                   from jaxns import NestedSampler, Model, Prior
                   from tensorflow_probability.substrates import jax as tfp
                   tfpd = tfp.distributions
                   from jaxns.utils import resample
               except ImportError:
                   raise ImportError("jaxns is required for the jaxns solver. Please install it.")

               print('Running jaxns on {}'.format(configpars['device']))
               
               # Configure device (optional, JAX usually handles this but we can force it if needed)
               # if configpars['device'] == 'cpu':
               #    jax.config.update("jax_platform_name", "cpu")
               
               # Get Likelihood
               log_likelihood = temp.get_jax_likelihood()
               
               # constant bounds
               bounds_list = temp.bounds
               # Flatten/stacked bounds
               # bounds is a list of (min, max)
               lowers = np.array([b[0] for b in bounds_list])
               uppers = np.array([b[1] for b in bounds_list])
               ptps = uppers - lowers
               
               lowers_j = jnp.array(lowers)
               uppers_j = jnp.array(uppers)
               
               def prior_model():
                   p = yield Prior(tfpd.Uniform(low=lowers_j, high=uppers_j), name='p')
                   return p
               
               # JAXNS Model
               model = Model(prior_model=prior_model, log_likelihood=log_likelihood)
               
               # Settings
               settings_dict = {'max_samples': 1e5} # Defaults
               if 'jaxns_settings' in configpars:
                   # Map settings
                   pass # Implement specific settings mapping if needed

               ns = NestedSampler(model=model)
               
               t0 = datetime.datetime.now()
               termination_reason, state = ns(key=jax.random.PRNGKey(42))
               t1 = datetime.datetime.now()
               print('Execution time {}'.format(t1-t0))
               
               # Extract results
               results = ns.to_results(state=state, termination_reason=termination_reason)
               
               # Save stats
               stats_file = configpars['chaindir'] + configpars['chainfmt'].format(configpars['nfill']) + '.stats'
               with open(stats_file, 'w') as f:
                   f.write('log(Z)   : {}   {}\n'.format(float(results.log_Z_mean), float(results.log_Z_uncert)))

               # Resample to equal weights
               key = jax.random.PRNGKey(42)
               
               samples_dict = results.samples
               log_weights = results.log_dp_mean 
               
               # samples_dict['p'] is the array we want (since we named it 'p' in prior_model)
               if 'p' in samples_dict:
                   samples_raw = samples_dict['p']
               else:
                   samples_raw = list(samples_dict.values())[0] 
                   
               # Resample samples and logL
               # We resample with replacement to get equal weights
               S_resample = int(settings_dict.get('max_samples', 1000))
               samples_equal = resample(key=key, samples=samples_raw, log_weights=log_weights, S=S_resample, replace=True)
               log_L_equal = resample(key=key, samples=results.log_L_samples, log_weights=log_weights, S=S_resample, replace=True)
               
               # Construct output matrix for pc_analyzer
               # [weight, -2*logL, p1, p2, ...]
               N_samples = samples_equal.shape[0]
               weights_col = np.ones((N_samples, 1))
               
               # pc_analyzer expects col 1 to be -2*ln(L)
               # lln = -0.5 * col1 => col1 = -2 * lln
               logL_col = -2.0 * log_L_equal.reshape(-1, 1) 
               
               samples_out = samples_equal.reshape(N_samples, -1)
               
               output_matrix = np.hstack([weights_col, logL_col, samples_out])
               
               chain_file = configpars['chaindir'] + configpars['chainfmt'].format(configpars['nfill']) + '_equal_weights.txt'
               np.savetxt(chain_file, output_matrix)
               print(f"Saved results to {chain_file}")

           else:
                 print('Requested solver {} not implemented'.format(solver))

if configpars['doplot']:
     
     #This can only be one on one core....
     print('Analyzing run: '+configpars['chainfmt'].format('',''))
        
     if os.path.exists(configpars['chaindir']+configpars['chainfmt'].format(configpars['nfill'])+'_equal_weights.txt'): 
            
            with fitter.als_fitter(configpars['specfile'], configpars['wavefit'], configpars['linelist'], configpars['ncomp'], \
                                 nfill=configpars['nfill'], coldef=configpars['coldef'], contval=configpars['contval'], \
                                 specres=configpars['specres'], Nrange=configpars['Nrange'], brange=configpars['brange'], \
                                 zrange=configpars['zrange'], Nrangefill=configpars['Nrangefill'], \
                                 brangefill=configpars['brangefill'], wrangefill=configpars['wrangefill'], Asymmlike=configpars['asymmlike'], \
                                 debug=args.debug) as temp:
                          
              lnz, dlnz, lhoodval, values = fitter.pc_analyzer(configpars['chaindir']+configpars['chainfmt'].format(temp.nfill), return_sorted=True)
              
              #Define parameter names
              parameters = fitter.get_parnames(temp.ncompmax+temp.nfill, temp.freecont)
        
              meds = np.nanpercentile(values, 50, axis=0) 
              percs = np.transpose(np.nanpercentile(values, [16,50,84], axis=0))
              
              if len(temp.contval)>1:
                 if len(temp.specres)>1:
                   continuum = meds[1]
                 else:
                   continuum = meds[0]  
              else:
                 continuum = temp.contval 
              
              if len(temp.specres)>1:
                 specresolution = meds[0]
              else:
                 specresolution = temp.specres   
              
              ncomp_arr, ncomp_counts = np.unique(values[:,temp.startind], return_counts=True)
              ncomp_counts = 1.*ncomp_counts/np.sum(ncomp_counts)
              
              #Calc median likelihood across posterior
              lnlhood = np.percentile(lhoodval, 50)
              AIC = 2*temp.ndim-2*lnlhood
              chi2 = temp.chi2(meds)
              statstring = r'$\ln(z): {0:6.3f},~\ln(L): {1:6.3f},~\chi^2: {2:6.3f},~AIC: {3:6.3f}$'.format(lnz, lnlhood, AIC, chi2)
              
              #{0:02d}
              print('________________________________________________________________' )             
              print('| Ln(z): {0:6.3f}, Ln(L): {1:6.3f}, Chi2: {2:6.3f}, AIC: {3:6.3f}'.format(lnz, lnlhood, AIC, chi2))
              for cc in range(len(ncomp_arr)):
                print('| Ncomp: {0:02d} Occurrence Fraction: {1:4.3f}'.format(int(ncomp_arr[cc]), ncomp_counts[cc]))
              print('|_______________________________________________________________' )             
              
              map_ncomp = int(ncomp_arr[np.argmax(ncomp_counts)])
                               
              nrows = (temp.numfitranges // configpars['nmaxcols'] )
              if temp.numfitranges % configpars['nmaxcols'] > 0:
                 nrows += 1
                 
              if nrows == 1:
                 ncols = temp.numfitranges
              else:
                 ncols = configpars['nmaxcols']   
                                               
              figsize = (10*ncols,5.5*nrows)
              fig, ax = pl.subplots(nrows=int(nrows), ncols=int(ncols), sharey=True, figsize=figsize, squeeze=False)
              
              
              nsamp = min([len(values),100])
              if nsamp< 100:
                 rsamples = np.arange(nsamp)
              else:
                 rsamples = np.random.randint(values.shape[0], size=nsamp)
              
              for waverange in range(temp.numfitranges):
                
                colind = int(waverange % configpars['nmaxcols'])
                rowind = int(waverange / configpars['nmaxcols'])
                
                ax[rowind,colind].step(temp.obj_wl, temp.obj, color='black', where='mid', lw=1)
                ax[rowind,colind].plot(temp.obj_wl, temp.obj_noise, '-b', lw=0.5)
                ax[rowind,colind].set_xlim(configpars['wavefit'][waverange])
                ax[rowind,colind].set_ylim(configpars['yrange'])
                        
                for ii in rsamples:
                    tsamp = values[ii,:]
                    tspec = temp.reconstruct_spec(tsamp)
                    
                    ax[rowind,colind].plot(temp.obj_wl, tspec, color='red', alpha=1-8E-3*nsamp, lw=2-1.7E-2*nsamp, rasterized=False)

                for i in range(temp.ncompmax+temp.nfill):
                    
                    _N, _z, _b = meds[1+3*i+temp.startind+np.arange(3)]
                    
                    if _z<10 and i<=map_ncomp:
                       color = 'dodgerblue'
                       spec1 = temp.reconstruct_onecomp(specresolution, continuum, _N, _z, _b)
                       
                       #Plot ticks at component positions, needs to be done for all 
                       #transitions in the plotted range
                       for trans in range(temp.numlines):
                          wave = temp.linepars[trans]['wrest'].value*(1+_z)
                          ax[rowind,colind].plot([wave, wave], [1.06, 1.10], color='blue')
                       
                    else:
                       color = 'salmon' 
                       spec1 = temp.reconstruct_onecomp_fill(specresolution, continuum, _N, _z, _b)  
                       
                       wave = temp.linefill['wrest'].value*(1+_z)
                       ax[rowind,colind].plot([wave, wave], [1.06, 1.10], color='red')

                    ax[rowind,colind].plot(temp.obj_wl, spec1, color=color, ls='dotted', lw=0.8, zorder=1)
                    
        
              fig.tight_layout()
              
              #pl.show()
              pl.subplots_adjust(top=0.91)
              pl.text(0.04,0.93,statstring,ha='left', transform=fig.transFigure)
              
              pl.savefig(configpars['plotdir']+configpars['chainfmt'].format(temp.nfill)+'.pdf')
              print('PDF written at: {}'.format(configpars['plotdir']+configpars['chainfmt'].format(temp.nfill)+'.pdf'))
              print('End of Job.')
